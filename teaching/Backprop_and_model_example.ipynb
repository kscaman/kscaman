{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3VzA28UUQOvo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a CNN using torchvision\n",
        "model_vgg = models.vgg16(weights='DEFAULT')\n",
        "print(model_vgg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_CTUfUbQUHP",
        "outputId": "1be96e18-e256-4d62-9e91-c64ded90c9fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 120MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a custom DL architecture (here a simple linear model...)\n",
        "class NewModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(3, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)"
      ],
      "metadata": {
        "id": "mgixNmLeQeVV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using backward for the computation of the gradient\n",
        "x = torch.Tensor([1, 0, 1])\n",
        "x.requires_grad = True\n",
        "\n",
        "model = NewModel()\n",
        "y = torch.sum(model(x))\n",
        "\n",
        "print(\"Before backprop:\", x.grad)\n",
        "\n",
        "y.backward()\n",
        "\n",
        "print(\"After backprop:\", x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jeXZ-OQRGXX",
        "outputId": "9d85a888-e63d-462e-9edd-ac60438e9887"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before backprop: None\n",
            "After backprop: tensor([-0.1076,  0.5554, -0.5603])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a typical training pipeline"
      ],
      "metadata": {
        "id": "ndwVx3qNQEqH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-NuHZQyQBCu"
      },
      "outputs": [],
      "source": [
        "### PARAMETERS\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 100\n",
        "\n",
        "### DATA, MODEL, LOSS, OPTIMIZER AND SCHEDULER\n",
        "dataloader = ... # YOUR DATA\n",
        "model = ... # YOUR MODEL\n",
        "criterion = ... # YOUR LOSS FUNCTION\n",
        "optimizer = ... # YOUR OPTIMIZER\n",
        "scheduler = ... # YOUR SCHEDULER\n",
        "\n",
        "### TRAINING LOOP\n",
        "# Prepares the model for training (needed for some models)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # One training epoch over the whole dataset\n",
        "    for inputs, targets in dataloader:\n",
        "        # One mini-batch, put on the desired devide (cpu or gpu)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Reinitialize the gradients before any computation\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Computation of the model's output and loss on the mini-batch\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Computation of the gradient on the mini-batch\n",
        "        loss.backward()\n",
        "\n",
        "        # One iteration of the optimizer and update of the step-size\n",
        "        optimizer.step()\n",
        "\n",
        "        # Then we can compute statistics and store loss values\n",
        "        ...\n",
        "\n",
        "    # Update of the step-size\n",
        "    scheduler.step()\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(..., ...))"
      ]
    }
  ]
}